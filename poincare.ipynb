{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import logging\n",
    "from hype.sn import Embedding \n",
    "from hype import train\n",
    "from hype.graph import load_edge_list, eval_reconstruction\n",
    "from hype.rsgd import RiemannianSGD\n",
    "from hype.Poincare import PoincareManifold\n",
    "import sys\n",
    "import json\n",
    "import torch.multiprocessing as mp\n",
    "from hype.graph_dataset import BatchedDataset\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters; these are global in the notebook!\n",
    "opt_maxnorm = 500000; opt_debug = False; opt_epochs = 1000; \n",
    "opt_manifold = \"Poincare\"; opt_dim = 2; opt_com_n = 1;\n",
    "opt_negs = 50; opt_batchsize = 10; opt_eval_each = 20;\n",
    "opt_sparse = True; opt_ndproc = 4;  opt_burnin = 20;\n",
    "opt_dampening = 0.75; opt_neg_multiplier = 1.0; \n",
    "opt_burnin_multiplier = 0.01; opt_lr = 0.3 \n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing logging and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using edge list dataloader\n"
     ]
    }
   ],
   "source": [
    "log_level = logging.DEBUG if opt_debug else logging.INFO\n",
    "log = logging.getLogger('Poincare')\n",
    "logging.basicConfig(level=log_level, format='%(message)s', stream=sys.stdout)\n",
    "log.info('Using edge list dataloader')\n",
    "idx, objects, weights = load_edge_list(\"wordnet/mammal_closure.csv\", False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(manifold, idx, objects, weights, sparse=True):\n",
    "    conf = []\n",
    "    model_name = '%s_dim%d%com_n'\n",
    "    mname = model_name % (opt_manifold, opt_dim, opt_com_n)\n",
    "    data = BatchedDataset(idx, objects, weights, opt_negs, opt_batchsize,\n",
    "        opt_ndproc, opt_burnin > 0, opt_dampening)\n",
    "    model = Embedding(len(data.objects), opt_dim, manifold, sparse=sparse, com_n=opt_com_n)\n",
    "    data.objects = objects\n",
    "    return model, data, mname, conf\n",
    "\n",
    "def adj_matrix(data):\n",
    "  adj = {}\n",
    "  for inputs, _ in data:\n",
    "    for row in inputs:\n",
    "        x = row[0].item()\n",
    "        y = row[1].item()\n",
    "        if x in adj:\n",
    "            adj[x].add(y)\n",
    "        else:\n",
    "            adj[x] = {y}\n",
    "  return adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_lr(data, epoch, progress = False):\n",
    "  data.burnin = False \n",
    "  lr = opt_lr\n",
    "  if epoch < opt_burnin:\n",
    "    data.burnin = True\n",
    "    lr = opt_lr * train._lr_multiplier\n",
    "  loader_iter = tqdm(data) if progress else data\n",
    "  return loader_iter, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, model, data, optimizer, progress=False):  \n",
    "  epoch_loss = torch.Tensor(len(data))\n",
    "  LOSS = np.zeros(opt_epochs)\n",
    "  \n",
    "  for epoch in range(opt_epochs):\n",
    "    largest_weight_emb = round(torch.abs(model.lt.weight.data).max().item(), 6)\n",
    "    print(largest_weight_emb, \"is the largest absolute weight in the embedding\")\n",
    "    \n",
    "    epoch_loss.fill_(0)\n",
    "    t_start = timeit.default_timer()\n",
    "    # handling burnin, get loader_iter and learning rate\n",
    "    loader_iter, lr = data_loader_lr(data, epoch, progress = progress)\n",
    "    \n",
    "    for i_batch, (inputs, targets) in enumerate(loader_iter):\n",
    "      elapsed = timeit.default_timer() - t_start\n",
    "      inputs = inputs.to(device); targets = targets.to(device)      \n",
    "      optimizer.zero_grad()\n",
    "      preds = model(inputs)\n",
    "      loss = model.loss(preds, targets, size_average=True)\n",
    "      loss.backward()\n",
    "      optimizer.step(lr=lr)\n",
    "      epoch_loss[i_batch] = loss.cpu().item()\n",
    "      \n",
    "    LOSS[epoch] = torch.mean(epoch_loss).item()\n",
    "    # since only one thread is used:\n",
    "    log.info('json_stats: {' f'\"epoch\": {epoch}, ' \\\n",
    "    f'\"elapsed\": {elapsed}, ' f'\"loss\": {LOSS[epoch]}, ' '}')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>> The size of embedding: Embedding(1180, 2, sparse=True)\n",
      "the total dimension 2 com_n 1\n",
      "0.0001 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 0, \"elapsed\": 0.8829694529995322, \"loss\": 3.930995959724351, }\n",
      "0.004032 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 1, \"elapsed\": 0.8684672829986084, \"loss\": 3.928955308060497, }\n",
      "0.007692 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 2, \"elapsed\": 0.8662014020010247, \"loss\": 3.9268697741719647, }\n",
      "0.011494 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 3, \"elapsed\": 0.85880389099475, \"loss\": 3.924800055566165, }\n",
      "0.015251 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 4, \"elapsed\": 0.8547810270029004, \"loss\": 3.9227158709103596, }\n",
      "0.018974 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 5, \"elapsed\": 0.8750297669976135, \"loss\": 3.920628796330075, }\n",
      "0.022722 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 6, \"elapsed\": 0.8799088039959315, \"loss\": 3.9185376716386995, }\n",
      "0.026399 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 7, \"elapsed\": 0.8775444579951, \"loss\": 3.9164586412306392, }\n",
      "0.030071 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 8, \"elapsed\": 0.877697072995943, \"loss\": 3.914420571844919, }\n",
      "0.033715 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 9, \"elapsed\": 0.8684990719993948, \"loss\": 3.9123602457382103, }\n",
      "0.037315 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 10, \"elapsed\": 0.8789810009984649, \"loss\": 3.9102918061697265, }\n",
      "0.040894 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 11, \"elapsed\": 0.8983326050001779, \"loss\": 3.9082690294552553, }\n",
      "0.044428 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 12, \"elapsed\": 0.8542255119973561, \"loss\": 3.9062442421701506, }\n",
      "0.047932 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 13, \"elapsed\": 0.8543541239996557, \"loss\": 3.904269002297247, }\n",
      "0.051412 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 14, \"elapsed\": 0.8608001290049287, \"loss\": 3.902206307859229, }\n",
      "0.054845 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 15, \"elapsed\": 0.8907047120010247, \"loss\": 3.9002369143013094, }\n",
      "0.058281 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 16, \"elapsed\": 0.8854041049999068, \"loss\": 3.8981995544977335, }\n",
      "0.061734 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 17, \"elapsed\": 0.8577535600052215, \"loss\": 3.896247101785545, }\n",
      "0.065104 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 18, \"elapsed\": 0.860523365001427, \"loss\": 3.894225670241357, }\n",
      "0.068491 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 19, \"elapsed\": 0.8727854739991017, \"loss\": 3.892331836548443, }\n",
      "0.071801 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 20, \"elapsed\": 1.0977794420032296, \"loss\": 3.8910868530335985, }\n",
      "0.142408 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 21, \"elapsed\": 1.1166597500050557, \"loss\": 3.7910560184317843, }\n",
      "0.211839 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 22, \"elapsed\": 1.1059286019954016, \"loss\": 3.6915984882296558, }\n",
      "0.294702 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 23, \"elapsed\": 1.123075133000384, \"loss\": 3.5984587663340104, }\n",
      "0.352717 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 24, \"elapsed\": 1.0940298499990604, \"loss\": 3.5153707111316024, }\n",
      "0.41762 is the largest absolute weight in the embedding\n"
     ]
    }
   ],
   "source": [
    "# setup model\n",
    "manifold = PoincareManifold(\n",
    "    debug=opt_debug, max_norm=opt_maxnorm, com_n=opt_com_n)\n",
    "model, data, model_name, conf = init_model(\n",
    "    manifold, idx, objects, weights, sparse=opt_sparse)\n",
    "data.neg_multiplier = opt_neg_multiplier\n",
    "train._lr_multiplier = opt_burnin_multiplier\n",
    "model = model.to(device)\n",
    "print('the total dimension', model.lt.weight.data.size(-1), 'com_n', opt_com_n)\n",
    "\n",
    "# setup optimizer\n",
    "optimizer = RiemannianSGD(model.optim_params(manifold), lr= opt_lr)\n",
    "# get adjacency matrix\n",
    "adj = adj_matrix(data) \n",
    "# begin training\n",
    "start_time = timeit.default_timer()\n",
    "train(device, model, data, optimizer, progress=False )\n",
    "print(\"Total training time is:\", timeit.default_timer() - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_stats final test: \n",
      "{\"sqnorm_min\": 0.031376, \"sqnorm_avg\": 0.90552, \"sqnorm_max\": 0.998303, \n",
      "\"mean_rank\": 59.716361, \"map\": 0.188161, }\n",
      "tensor([-0.6685, -0.6831])\n"
     ]
    }
   ],
   "source": [
    "meanrank, maprank = eval_reconstruction(\n",
    "    adj, model.lt.weight.data.clone(), manifold.distance, workers=opt_ndproc)\n",
    "sqnorms = manifold.pnorm(model.lt.weight.data.clone())\n",
    "log.info(\n",
    "        'json_stats final test: \\n{' \n",
    "        f'\"sqnorm_min\": {round(sqnorms.min().item(),6)}, '\n",
    "        f'\"sqnorm_avg\": {round(sqnorms.mean().item(),6)}, '\n",
    "        f'\"sqnorm_max\": {round(sqnorms.max().item(),6)}, \\n'\n",
    "        f'\"mean_rank\": {round(meanrank,6)}, '\n",
    "        f'\"map\": {round(maprank,6)}, '\n",
    "        '}'\n",
    "    )\n",
    "print(model.lt.weight.data[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a0267f670e2b0941e569fb4138371a40e75b428fb955a02da7bcb7cd596bc5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
