{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import logging\n",
    "from hype.sn import Embedding \n",
    "from hype import train\n",
    "from hype.graph import load_edge_list, eval_reconstruction\n",
    "from hype.rsgd import RiemannianSGD\n",
    "from hype.Poincare import PoincareManifold\n",
    "import sys\n",
    "import json\n",
    "import torch.multiprocessing as mp\n",
    "from hype.graph_dataset import BatchedDataset\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters; these are global in the notebook!\n",
    "opt_maxnorm = 500000; opt_com_n = 2; opt_debug = False\n",
    "opt_manifold = \"Poincare\"; opt_dim = 2; opt_com_n = 1;\n",
    "opt_negs = 50; opt_batchsize = 10; opt_eval_each = 20;\n",
    "opt_sparse = True; opt_ndproc = 4;  opt_burnin = 20;\n",
    "opt_dampening = 0.75; opt_neg_multiplier = 1.0; \n",
    "opt_burnin_multiplier = 0.01; opt_lr = 0.3 \n",
    "#######################################\n",
    "opt_epochs = 1000; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing logging and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using edge list dataloader\n"
     ]
    }
   ],
   "source": [
    "log_level = logging.DEBUG if opt_debug else logging.INFO\n",
    "log = logging.getLogger('Poincare')\n",
    "logging.basicConfig(level=log_level, format='%(message)s', stream=sys.stdout)\n",
    "log.info('Using edge list dataloader')\n",
    "idx, objects, weights = load_edge_list(\"wordnet/mammal_closure.csv\", False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(manifold, idx, objects, weights, sparse=True):\n",
    "    conf = []\n",
    "    model_name = '%s_dim%d%com_n'\n",
    "    mname = model_name % (opt_manifold, opt_dim, opt_com_n)\n",
    "    data = BatchedDataset(idx, objects, weights, opt_negs, opt_batchsize,\n",
    "        opt_ndproc, opt_burnin > 0, opt_dampening)\n",
    "    model = Embedding(len(data.objects), opt_dim, manifold, sparse=sparse, com_n=opt_com_n)\n",
    "    data.objects = objects\n",
    "    return model, data, mname, conf\n",
    "\n",
    "def adj_matrix(data):\n",
    "  adj = {}\n",
    "  for inputs, _ in data:\n",
    "    for row in inputs:\n",
    "        x = row[0].item(); y = row[1].item()\n",
    "        if x in adj:\n",
    "            adj[x].add(y)\n",
    "        else:\n",
    "            adj[x] = {y}\n",
    "  return adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_lr(data, epoch, progress = False):\n",
    "  data.burnin = True \n",
    "  lr = opt_lr\n",
    "  if epoch < opt_burnin:\n",
    "    data.burnin = True\n",
    "    lr = opt_lr * opt_burnin_multiplier\n",
    "  loader_iter = tqdm(data) if progress else data\n",
    "  return loader_iter, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(device, model, data, optimizer, progress=False):\n",
    "  \n",
    "  epoch_loss = torch.Tensor(len(data))\n",
    "  LOSS = np.zeros(opt_epochs)\n",
    "  \n",
    "  for epoch in range(opt_epochs):\n",
    "    largest_weight_emb = round(torch.abs(model.lt.weight.data).max().item(), 6)\n",
    "    print(largest_weight_emb, \"is the largest absolute weight in the embedding\")\n",
    "    \n",
    "    epoch_loss.fill_(0)\n",
    "    t_start = timeit.default_timer()\n",
    "    # handling burnin, get loader_iter and learning rate\n",
    "    loader_iter, lr = data_loader_lr(data, epoch, progress = progress)\n",
    "    \n",
    "    for i_batch, (inputs, targets) in enumerate(loader_iter):\n",
    "      elapsed = timeit.default_timer() - t_start\n",
    "      inputs = inputs.to(device); targets = targets.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      preds = model(inputs)\n",
    "      loss = model.loss(preds, targets, size_average=True)\n",
    "      loss.backward()\n",
    "      optimizer.step(lr=lr)\n",
    "      epoch_loss[i_batch] = loss.cpu().item()\n",
    "    LOSS[epoch] = torch.mean(epoch_loss).item()\n",
    "    # since only one thread is used:\n",
    "    log.info('json_stats: {' f'\"epoch\": {epoch}, ' \\\n",
    "    f'\"elapsed\": {elapsed}, ' f'\"loss\": {LOSS[epoch]}, ' '}')\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger Poincare (INFO)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>> The size of embedding: Embedding(1180, 2, sparse=True)\n",
      "the total dimension 2 com_n 1\n",
      "0.0001 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 0, \"elapsed\": 0.9979415950001567, \"loss\": 3.9309851805430984, }\n",
      "0.004004 is the largest absolute weight in the embedding\n",
      "json_stats: {\"epoch\": 1, \"elapsed\": 0.840299869003502, \"loss\": 3.928934140871777, }\n",
      "0.00775 is the largest absolute weight in the embedding\n"
     ]
    }
   ],
   "source": [
    "# setup model\n",
    "manifold = PoincareManifold(\n",
    "    debug=opt_debug, max_norm=opt_maxnorm, com_n=opt_com_n)\n",
    "model, data, model_name, conf = init_model(\n",
    "    manifold, idx, objects, weights, sparse=opt_sparse)\n",
    "data.neg_multiplier = opt_neg_multiplier\n",
    "model = model.to(device)\n",
    "print('the total dimension', model.lt.weight.data.size(-1), 'com_n', opt_com_n)\n",
    "\n",
    "# setup optimizer\n",
    "optimizer = RiemannianSGD(model.optim_params(manifold), lr= opt_lr)\n",
    "# get adjacency matrix\n",
    "adj = adj_matrix(data) \n",
    "# begin training\n",
    "start_time = timeit.default_timer()\n",
    "train(device, model, data, optimizer, progress=False )\n",
    "print(\"Total training time is:\", timeit.default_timer() - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_stats final test: \n",
      "{\"sqnorm_min\": 0.049918, \"sqnorm_avg\": 0.87429, \"sqnorm_max\": 0.999998, \n",
      "\"mean_rank\": 434.161774, \"map\": 0.016397, }\n"
     ]
    }
   ],
   "source": [
    "meanrank, maprank = eval_reconstruction(\n",
    "    adj, model.lt.weight.data.clone(), manifold.distance, workers=opt_ndproc)\n",
    "sqnorms = manifold.pnorm(model.lt.weight.data.clone())\n",
    "log.info(\n",
    "        'json_stats final test: \\n{' \n",
    "        f'\"sqnorm_min\": {round(sqnorms.min().item(),6)}, '\n",
    "        f'\"sqnorm_avg\": {round(sqnorms.mean().item(),6)}, '\n",
    "        f'\"sqnorm_max\": {round(sqnorms.max().item(),6)}, \\n'\n",
    "        f'\"mean_rank\": {round(meanrank,6)}, '\n",
    "        f'\"map\": {round(maprank,6)}, '\n",
    "        '}'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a0267f670e2b0941e569fb4138371a40e75b428fb955a02da7bcb7cd596bc5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
